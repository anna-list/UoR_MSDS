{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d4136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys\n",
    "\n",
    "ACCESS_TOKEN = \"1048198054044557313-7Gg2KsT5BdXMms2YYUSMBDJcvqpz50\"\n",
    "ACCESS_TOKEN_SECRET = \"00LmyoLAHAcPpHNNaqNWinUj3LtRMeOXyQ9tlsyxWwDBf\"\n",
    "CONSUMER_KEY = \"SH0QQe5G2qVyUfWiUQ0ziNE0l\"\n",
    "CONSUMER_SECRET = \"TIVBEbOiagfoabCVoOg3wEed5QoefrwZUl57tRIIC5bAraWz5x\"\n",
    "\n",
    "# BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAP1PjAEAAAAAVNecFA9PZ8bDLjTNhcZJvOTWs2A%3DnLM6ySxCM3RzcH35ZMiFAZYaQiLXfZda9uy4trNIYeXR8ML67Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auth\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) \n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET) \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "\n",
    "# client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "city_data = pd.read_csv('~/Documents/Practice/NEW_ORLEANS.csv', header=None, dtype=str)\n",
    "Columns = [\"Tweet\", \"Tweet-id\", \"Time(Month-Year)\"]\n",
    "city_data.columns = Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a738215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare mapping for tweet-id with it's MonthYear\n",
    "\n",
    "tweets_dict = {}\n",
    "for index, row in city_data.iterrows():\n",
    "    if index == 0:\n",
    "        continue\n",
    "    tweets_dict[row['Tweet-id']] = row['Time(Month-Year)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c423406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Tweet-ids\n",
    "\n",
    "tweet_ids = list(tweets_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = []\n",
    "# for tweet_id in tweet_ids:\n",
    "#     out = client.get_tweets(tweet_id, expansions='author_id', user_fields='id')\n",
    "#     user_id = out.includes.get('users')[0] if out.includes.get('users') else None\n",
    "#     if user_id:\n",
    "#         users.append(user_id.get('id'))\n",
    "#     else:\n",
    "#         user.append(None)\n",
    "# len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Detailed Tweet Lookup Code, given tweet-id\n",
    "\n",
    "out = api.lookup_statuses(id=list(tweet_ids[:10]), map=True)\n",
    "# out = api.get_status(','.join(tweet_ids[:10]))\n",
    "\n",
    "followers = out[0]._json.get('user').get('followers_count') if out[0]._json.get('user') else None\n",
    "verified = out[0]._json.get('user').get('verified') if out[0]._json.get('user') else None\n",
    "geo = out[0]._json.get('geo').get('coordinates') if out[0]._json.get('geo') else None\n",
    "geo = ','.join([str(g) for g in geo]) if geo else None\n",
    "hashtags = out[0]._json.get('entities').get('hashtags') if out[0]._json.get('entities') else None\n",
    "hashtags = ','.join([h.get('text') for h in hashtags])\n",
    "created_at = out[0]._json.get('created_at')\n",
    "user_created_at = out[0]._json.get('user').get('created_at') if out[0]._json.get('user') else None\n",
    "retweet_count = out[0]._json.get('retweet_count')\n",
    "lang = out[0]._json.get('lang', None)\n",
    "tweet_id = out[0]._json.get('id_str')\n",
    "tweet_text = out[0]._json.get('text')\n",
    "\n",
    "followers, verified, geo, hashtags, created_at, user_created_at, retweet_count, lang, tweet_id, tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca53a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare chunks for 100 tweets, as the api allows maximum 100 tweet-ids to be sent at once\n",
    "\n",
    "chunk_size = 100\n",
    "chunked_tweets = [tweet_ids[i:i + chunk_size] for i in range(0, len(tweet_ids), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c47fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare columns for our detailed tweet file by parsing api response\n",
    "\n",
    "def decode_json(output):\n",
    "    \n",
    "    user_id = followers = verified = user_created_at = geo = hashtags = None\n",
    "    \n",
    "    tweet_created_at = output._json.get('created_at', None)\n",
    "    retweet_count = output._json.get('retweet_count', None)\n",
    "    lang = output._json.get('lang', None)\n",
    "    tweet_id = output._json.get('id_str', None)\n",
    "    tweet_text = output._json.get('text')\n",
    "    \n",
    "    time = tweets_dict.get(tweet_id)\n",
    "    \n",
    "    if output._json and output._json.get('user'):\n",
    "        user = output._json.get('user')\n",
    "        user_id = user.get('id', None)\n",
    "        followers = user.get('followers_count', None)\n",
    "        verified = user.get('verified', None)\n",
    "        user_created_at = user.get('created_at', None)\n",
    "        \n",
    "    if output._json and output._json.get('geo'):\n",
    "        geo = output._json.get('geo').get('coordinates', None)\n",
    "        geo = ','.join([str(g) for g in geo]) if geo else None\n",
    "        \n",
    "    if output._json.get('entities'):\n",
    "        hashtags = output._json.get('entities').get('hashtags')\n",
    "        hashtags = ','.join([h.get('text') for h in hashtags]) if hashtags else None\n",
    "    \n",
    "    if not user_id:\n",
    "        return None\n",
    "        \n",
    "    return {'Tweet': tweet_text, 'Tweet_id': tweet_id, 'User_id': user_id, 'User_created_at': user_created_at,\n",
    "           'Followers': followers, 'User_verfied': verified, 'Geo': geo, 'Hashtags': hashtags, \n",
    "           'retweet_count': retweet_count, 'lang': lang, 'Tweet_created_at': tweet_created_at, \"Time(Month-Year)\": time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fefacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver function to do api call and save parsed responses in file\n",
    "\n",
    "i = 0\n",
    "unrecognized_tweets = []\n",
    "file_name = 'NEW_ORLEANS_Detailed.csv'\n",
    "\n",
    "for tweet_ids in chunked_tweets:\n",
    "    print(\"loop {} out of {}\".format(i, len(chunked_tweets)))\n",
    "    try:\n",
    "        out = api.lookup_statuses(list(tweet_ids), map=True)\n",
    "        for output in out:\n",
    "            row = decode_json(output)\n",
    "            if not row:\n",
    "                unrecognized_tweets.append(output)\n",
    "                continue   #Skip tweet which doesn't have any information being retrieved from tweet_id\n",
    "            df = pd.DataFrame(row, index=[1])\n",
    "            df.to_csv(file_name, mode='a', index=False, header=False)\n",
    "    except Exception as e:\n",
    "        print(\"{}\\n\".format(e))\n",
    "    i += 1\n",
    "\n",
    "city_data = pd.read_csv('~/Documents/Practice/NEW_ORLEANS_Detailed.csv', header=None, dtype=str)\n",
    "Columns = [\"Tweet\", \"Tweet-id\", \"User_id\", \"User_created_at\", \"Followers\", \"User_verfied\", \"Geo\",\n",
    "           \"Hashtags\", \"retweet_count\", \"lang\", \"Tweet_created_at\", \"Time(Month-Year)\"]\n",
    "city_data.columns = Columns\n",
    "city_data.to_csv(file_name, index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
